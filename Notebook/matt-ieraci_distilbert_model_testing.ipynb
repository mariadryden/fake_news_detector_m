{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, DistilBertConfig, create_optimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model for testing\n",
    "model_path = '../models/distilbert_model_best.h5'\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# import tokenizer for testing\n",
    "tokenizer_path = '../tokenizers/distilbert_tokenizer_best'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dictionary for stopwords\n",
    "nltk.download('stopwords')\n",
    "# Get the set of stopwords\n",
    "stop_words_set = set(stopwords.words('english'))\n",
    "# Load English tokenizer from spacy\n",
    "nlp = English()\n",
    "spacy_tokenizer = nlp.tokenizer ## make instance\n",
    "# Create function to clean text -- lowercase, remove non alphanumeric, remove stop words\n",
    "def optimized_preprocess(text): ## Takes in a list of texts, i.e. the entire corpus\n",
    "    # Tokenize using spaCy’s tokenizer\n",
    "    tokens = [token.text.lower() for token in spacy_tokenizer(text) if token.text.isalpha() and token.text.lower() not in stop_words_set]\n",
    "    cleaned_query= ' '.join(word for word in tokens)\n",
    "    return cleaned_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unseen dataset for testing\n",
    "test_df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Seperate fake and true articles with random sample size variable\n",
    "sample_size = 100\n",
    "fake_df = test_df[test_df['label'] == 1].sample(sample_size)\n",
    "true_df = test_df[test_df['label'] == 0].sample(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16655</th>\n",
       "      <td>16655</td>\n",
       "      <td>Trump’s Camp Manager DESTROYS Hillary By Point...</td>\n",
       "      <td>Amanda Shea</td>\n",
       "      <td>Trump’s Camp Manager DESTROYS Hillary By Point...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19631</th>\n",
       "      <td>19631</td>\n",
       "      <td>October Surprise: ABC Uncovers “Millions” of P...</td>\n",
       "      <td>Colin Taylor</td>\n",
       "      <td>Comments \\nRepublican nominee Donald Trump has...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>3360</td>\n",
       "      <td>The Pathologization of Dissent</td>\n",
       "      <td>CJ Hopkins</td>\n",
       "      <td>Photo by Jamelle Bouie | CC BY 2.0 \\n\\nAccordi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>6160</td>\n",
       "      <td>8 Ways To Forge Strength Through Challenges</td>\n",
       "      <td>Corey Savage</td>\n",
       "      <td>8 Ways To Forge Strength Through Challenges ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12017</th>\n",
       "      <td>12017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patriots.bonfire</td>\n",
       "      <td>All eyes on Electoral delegates. The People kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>1820</td>\n",
       "      <td>These Blast Points on Hillary’s Campaign… Only...</td>\n",
       "      <td>Charles Hugh Smith</td>\n",
       "      <td>\\nThe Deep State’s most prescient elements mus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>1646</td>\n",
       "      <td>“Nothing Good Can Come of This Election”–and T...</td>\n",
       "      <td>Charles Hugh Smith</td>\n",
       "      <td>Posted on November 4, 2016 by Charles Hugh Smi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11591</th>\n",
       "      <td>11591</td>\n",
       "      <td>Obama Faults F.B.I. on Emails, Citing ‘Incompl...</td>\n",
       "      <td>Kaitlyn Stegall</td>\n",
       "      <td>November 3, 2016 Obama Faults F.B.I. on Emails...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>19574</td>\n",
       "      <td>U.S. Takes A Stab At A No Fly Zone In Two Plac...</td>\n",
       "      <td>Brandon Turbeville</td>\n",
       "      <td>By Brandon Turbeville As the United States mar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16542</th>\n",
       "      <td>16542</td>\n",
       "      <td>Hurricane Mathew vs. shock and awe of empire</td>\n",
       "      <td>Philip A Farruggio</td>\n",
       "      <td>Hurricane Mathew vs. shock and awe of empire B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "16655  16655  Trump’s Camp Manager DESTROYS Hillary By Point...   \n",
       "19631  19631  October Surprise: ABC Uncovers “Millions” of P...   \n",
       "3360    3360                     The Pathologization of Dissent   \n",
       "6160    6160        8 Ways To Forge Strength Through Challenges   \n",
       "12017  12017                                                NaN   \n",
       "...      ...                                                ...   \n",
       "1820    1820  These Blast Points on Hillary’s Campaign… Only...   \n",
       "1646    1646  “Nothing Good Can Come of This Election”–and T...   \n",
       "11591  11591  Obama Faults F.B.I. on Emails, Citing ‘Incompl...   \n",
       "19574  19574  U.S. Takes A Stab At A No Fly Zone In Two Plac...   \n",
       "16542  16542       Hurricane Mathew vs. shock and awe of empire   \n",
       "\n",
       "                   author                                               text  \\\n",
       "16655         Amanda Shea  Trump’s Camp Manager DESTROYS Hillary By Point...   \n",
       "19631        Colin Taylor  Comments \\nRepublican nominee Donald Trump has...   \n",
       "3360           CJ Hopkins  Photo by Jamelle Bouie | CC BY 2.0 \\n\\nAccordi...   \n",
       "6160         Corey Savage    8 Ways To Forge Strength Through Challenges ...   \n",
       "12017    patriots.bonfire  All eyes on Electoral delegates. The People kn...   \n",
       "...                   ...                                                ...   \n",
       "1820   Charles Hugh Smith  \\nThe Deep State’s most prescient elements mus...   \n",
       "1646   Charles Hugh Smith  Posted on November 4, 2016 by Charles Hugh Smi...   \n",
       "11591     Kaitlyn Stegall  November 3, 2016 Obama Faults F.B.I. on Emails...   \n",
       "19574  Brandon Turbeville  By Brandon Turbeville As the United States mar...   \n",
       "16542  Philip A Farruggio  Hurricane Mathew vs. shock and awe of empire B...   \n",
       "\n",
       "       label  \n",
       "16655      1  \n",
       "19631      1  \n",
       "3360       1  \n",
       "6160       1  \n",
       "12017      1  \n",
       "...      ...  \n",
       "1820       1  \n",
       "1646       1  \n",
       "11591      1  \n",
       "19574      1  \n",
       "16542      1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display fake df\n",
    "fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17824</th>\n",
       "      <td>17824</td>\n",
       "      <td>Snap Is Said to Have Worked on a Drone - The N...</td>\n",
       "      <td>Katie Benner</td>\n",
       "      <td>Snap has long been known as the maker of Snapc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14738</th>\n",
       "      <td>14738</td>\n",
       "      <td>Nintendo Switch: A Blast at Home, So-So on the...</td>\n",
       "      <td>Brian X. Chen</td>\n",
       "      <td>There’s a new gadget that you can count on to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>1639</td>\n",
       "      <td>Poll: 96% of Trump Supporters Would Vote for H...</td>\n",
       "      <td>Joel B. Pollak</td>\n",
       "      <td>An ABC   Post poll released on Sunday found th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>How the Fight for a National African-American ...</td>\n",
       "      <td>Graham Bowley</td>\n",
       "      <td>Eleven years ago, Lonnie G. Bunch III was a mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>13721</td>\n",
       "      <td>Swedish Journalist Attacked in ’No Go Zone’</td>\n",
       "      <td>Chris Tomlinson</td>\n",
       "      <td>A photographer for Dagens Nyheter, one of Swed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12027</th>\n",
       "      <td>12027</td>\n",
       "      <td>Review: Emmy Awards Showcase TV’s Cultural Dom...</td>\n",
       "      <td>James Poniewozik</td>\n",
       "      <td>Our full report on the 2016 Emmy Awards | red...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9834</th>\n",
       "      <td>9834</td>\n",
       "      <td>CNN Op-Ed: Saudis Loved Melania Trump Because ...</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>Bangladeshi pundit Anushay Hossain writes for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14864</th>\n",
       "      <td>14864</td>\n",
       "      <td>Jane Fawcett, British Decoder Who Helped Doom ...</td>\n",
       "      <td>Bruce Weber</td>\n",
       "      <td>Jane Fawcett, who was a reluctant London debut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>5844</td>\n",
       "      <td>Armstrong and Green: What Does the March for S...</td>\n",
       "      <td>J. Scott Armstrong and Kesten C. Green</td>\n",
       "      <td>What is the “Scientific method”? [Saturday’s M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14091</th>\n",
       "      <td>14091</td>\n",
       "      <td>China Announces It Will Block Imports of North...</td>\n",
       "      <td>John J. Xenakis</td>\n",
       "      <td>This morning’s key headlines from Generational...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "17824  17824  Snap Is Said to Have Worked on a Drone - The N...   \n",
       "14738  14738  Nintendo Switch: A Blast at Home, So-So on the...   \n",
       "1639    1639  Poll: 96% of Trump Supporters Would Vote for H...   \n",
       "274      274  How the Fight for a National African-American ...   \n",
       "13721  13721        Swedish Journalist Attacked in ’No Go Zone’   \n",
       "...      ...                                                ...   \n",
       "12027  12027  Review: Emmy Awards Showcase TV’s Cultural Dom...   \n",
       "9834    9834  CNN Op-Ed: Saudis Loved Melania Trump Because ...   \n",
       "14864  14864  Jane Fawcett, British Decoder Who Helped Doom ...   \n",
       "5844    5844  Armstrong and Green: What Does the March for S...   \n",
       "14091  14091  China Announces It Will Block Imports of North...   \n",
       "\n",
       "                                       author  \\\n",
       "17824                            Katie Benner   \n",
       "14738                           Brian X. Chen   \n",
       "1639                           Joel B. Pollak   \n",
       "274                             Graham Bowley   \n",
       "13721                         Chris Tomlinson   \n",
       "...                                       ...   \n",
       "12027                        James Poniewozik   \n",
       "9834                           Breitbart News   \n",
       "14864                             Bruce Weber   \n",
       "5844   J. Scott Armstrong and Kesten C. Green   \n",
       "14091                         John J. Xenakis   \n",
       "\n",
       "                                                    text  label  \n",
       "17824  Snap has long been known as the maker of Snapc...      0  \n",
       "14738  There’s a new gadget that you can count on to ...      0  \n",
       "1639   An ABC   Post poll released on Sunday found th...      0  \n",
       "274    Eleven years ago, Lonnie G. Bunch III was a mu...      0  \n",
       "13721  A photographer for Dagens Nyheter, one of Swed...      0  \n",
       "...                                                  ...    ...  \n",
       "12027   Our full report on the 2016 Emmy Awards | red...      0  \n",
       "9834   Bangladeshi pundit Anushay Hossain writes for ...      0  \n",
       "14864  Jane Fawcett, who was a reluctant London debut...      0  \n",
       "5844   What is the “Scientific method”? [Saturday’s M...      0  \n",
       "14091  This morning’s key headlines from Generational...      0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display true df\n",
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test on fake_df \n",
    "# -----WITH PREPROCESS FUNCTION-----\n",
    "\n",
    "# Create empty list to store results\n",
    "fake_check_list = []\n",
    "\n",
    "# Iterate through texts in the fake_df\n",
    "for text in fake_df.text:\n",
    "    # store preprocessed text in random_input variable\n",
    "    random_input = optimized_preprocess(text)\n",
    "    # tokenize the random input and return as a tensor\n",
    "    random_input = tokenizer.encode_plus(\n",
    "        random_input,\n",
    "        add_special_tokens=True,\n",
    "        max_length=300,\n",
    "        truncation = True,\n",
    "        padding='max_length', \n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    \n",
    "    # Extract 'input_ids' from the 'random_input' dictionary.\n",
    "    # (numerical representations of textual input for the model)\n",
    "    input_ids = random_input['input_ids']\n",
    "    \n",
    "    # Extract the 'attention_mask' from the 'random_input' dictionary. \n",
    "    # This mask helps the model focus on relevant parts of the input.\n",
    "    attention_mask = random_input['attention_mask']\n",
    "\n",
    "    # Pass the 'input_ids' and 'attention_mask' to the model to get predictions. \n",
    "    # The model uses these inputs to make predictions about the class of the input (Real or Fake).\n",
    "    predictions = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Apply the softmax function to the logits (raw outputs) of the model's predictions.\n",
    "    # Softmax converts logits to probabilities, making them easier to interpret.\n",
    "    probabilities = tf.nn.softmax(predictions.logits, axis=-1)\n",
    "\n",
    "    # Find the class with the highest probability as the model's final prediction.\n",
    "    # 'tf.argmax' returns the index of the highest value along the specified axis \n",
    "    # (-1 refers to the last axis).\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy()\n",
    "    \n",
    "    # Define the class names corresponding to the output of the model. \n",
    "    # In this case, the classes are 'Real' and 'Fake'.\n",
    "    class_names = ['Real', 'Fake']\n",
    "    \n",
    "    # Append a summary message to the 'fake_check_list'.\n",
    "    # This message includes the predicted class name and the associated probabilities for each class.\n",
    "    # The predicted class is identified by indexing into 'class_names' using 'predicted_class[0]'.\n",
    "    # Probabilities are converted to a numpy array for easier readability.\n",
    "    fake_check_list.append([f\"The article is predicted as: {class_names[predicted_class[0]]}\", f\"Probabilities per class: {probabilities.numpy()[0]}\"])\n",
    "    \n",
    "# Print test results\n",
    "fake_check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test on true_df \n",
    "# -----WITH PREPROCESS FUNCTION-----\n",
    "\n",
    "# refer to code block above for comments\n",
    "\n",
    "real_check_list = []\n",
    "for text in true_df.text:\n",
    "    random_input = optimized_preprocess(text)\n",
    "    random_input = tokenizer.encode_plus(\n",
    "        random_input,\n",
    "        add_special_tokens=True,\n",
    "        max_length=300,\n",
    "        truncation = True,\n",
    "        padding='max_length', \n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    input_ids = random_input['input_ids']\n",
    "    attention_mask = random_input['attention_mask']\n",
    "\n",
    "\n",
    "    predictions = model(input_ids, attention_mask=attention_mask)\n",
    "    probabilities = tf.nn.softmax(predictions.logits, axis=-1)\n",
    "\n",
    "\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy()\n",
    "    class_names = ['Real', 'Fake']\n",
    "    real_check_list.append([f\"The article is predicted as: {class_names[predicted_class[0]]}\", f\"Probabilities per class: {probabilities.numpy()[0]}\"])\n",
    "real_check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL ONLY ONCE\n",
    "\n",
    "# Create an empty dict to store results\n",
    "result_dict = {}\n",
    "\n",
    "# Start at test #1\n",
    "test_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test results in dict\n",
    "result_dict[f'test_{test_num}'] = {\n",
    "    # Sub dict for fake article test\n",
    "    'fake_examples': {\n",
    "        # Save indices of tested articles in list form\n",
    "        'indices': fake_df.index.tolist(),\n",
    "        # Save scores for test\n",
    "        'scores': fake_check_list\n",
    "    },\n",
    "    # Sub dict for true article test\n",
    "    'true_examples': {\n",
    "        # Save indices of tested articles in list form\n",
    "        'indices': true_df.index.tolist(),\n",
    "        # Save scores for test\n",
    "        'scores': real_check_list\n",
    "    }\n",
    "}\n",
    "# Increase test_num by one to prepare for next test\n",
    "test_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_1'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check keys of Dict to see how many tests have been stored\n",
    "result_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The article is predicted as: Real', 'Probabilities per class: [0.8440879  0.15591207]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.75991464 0.24008535]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.57415354 0.42584652]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.64537156 0.35462847]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.8273343  0.17266572]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.5161735  0.48382646]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.5240606  0.47593936]']\n",
      "Accuracy (Fake W/ Preprocessing) = 93%\n"
     ]
    }
   ],
   "source": [
    "# Calculate fake_df test accuracy\n",
    "# ------WITH PREPROCESSING------\n",
    "# Iterate through tests in the result_dict\n",
    "for test in result_dict.keys():\n",
    "    # Create a count variable to track results\n",
    "    count = 0\n",
    "    # Index to list of scores\n",
    "    for result in result_dict[test]['fake_examples']['scores']:\n",
    "        # For score in list of scores, if wrongly predicted:\n",
    "        for row in result:\n",
    "            if \"Real\" in row:\n",
    "                # Add one to count\n",
    "                count += 1\n",
    "                # Print row that was incorrect\n",
    "                print(result)\n",
    "\n",
    "# Print the accuracy for the test in question in percentage format\n",
    "print(f'Accuracy (Fake W/ Preprocessing) = {100 - count}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The article is predicted as: Fake', 'Probabilities per class: [0.23449449 0.7655055 ]']\n",
      "['The article is predicted as: Fake', 'Probabilities per class: [0.11451195 0.88548803]']\n",
      "['The article is predicted as: Fake', 'Probabilities per class: [0.48959827 0.51040167]']\n",
      "['The article is predicted as: Fake', 'Probabilities per class: [0.25674927 0.74325067]']\n",
      "['The article is predicted as: Fake', 'Probabilities per class: [0.09440463 0.9055954 ]']\n",
      "['The article is predicted as: Fake', 'Probabilities per class: [0.39327615 0.6067239 ]']\n",
      "['The article is predicted as: Fake', 'Probabilities per class: [0.44517723 0.5548228 ]']\n",
      "Accuracy (True W/ Preprocessing) = 93%\n"
     ]
    }
   ],
   "source": [
    "# Calculate true_df test accuracy\n",
    "# ------WITH PREPROCESSING------\n",
    "# refer to above cell block for comments\n",
    "for test in result_dict.keys():\n",
    "    count = 0\n",
    "    for result in result_dict[test]['true_examples']['scores']:\n",
    "        for row in result:\n",
    "            if \"Fake\" in row:\n",
    "                count += 1\n",
    "                print(result)\n",
    "print(f'Accuracy (True W/ Preprocessing) = {100 - count}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test on fake_df \n",
    "# -----WITHOUT PREPROCESS FUNCTION-----\n",
    "# Refer to test cell block above for comments\n",
    "\n",
    "no_preproc_fake_check_list = []\n",
    "for text in fake_df.text:\n",
    "    random_input = text\n",
    "    random_input = tokenizer.encode_plus(\n",
    "        random_input,\n",
    "        add_special_tokens=True,\n",
    "        max_length=300,\n",
    "        truncation = True,\n",
    "        padding='max_length', \n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    input_ids = random_input['input_ids']\n",
    "    attention_mask = random_input['attention_mask']\n",
    "\n",
    "\n",
    "    predictions = model(input_ids, attention_mask=attention_mask)\n",
    "    probabilities = tf.nn.softmax(predictions.logits, axis=-1)\n",
    "\n",
    "\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy()\n",
    "    class_names = ['Real', 'Fake']\n",
    "    no_preproc_fake_check_list.append([f\"The article is predicted as: {class_names[predicted_class[0]]}\", f\"Probabilities per class: {probabilities.numpy()[0]}\"])\n",
    "no_preproc_fake_check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test on true_df \n",
    "# -----WITHOUT PREPROCESS FUNCTION-----\n",
    "# Refer to test cell block above for comments\n",
    "\n",
    "no_preproc_real_check_list = []\n",
    "for text in true_df.text:\n",
    "    random_input = text\n",
    "    random_input = tokenizer.encode_plus(\n",
    "        random_input,\n",
    "        add_special_tokens=True,\n",
    "        max_length=300,\n",
    "        truncation = True,\n",
    "        padding='max_length', \n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    input_ids = random_input['input_ids']\n",
    "    attention_mask = random_input['attention_mask']\n",
    "\n",
    "\n",
    "    predictions = model(input_ids, attention_mask=attention_mask)\n",
    "    probabilities = tf.nn.softmax(predictions.logits, axis=-1)\n",
    "\n",
    "\n",
    "    predicted_class = tf.argmax(probabilities, axis=-1).numpy()\n",
    "    class_names = ['Real', 'Fake']\n",
    "    no_preproc_real_check_list.append([f\"The article is predicted as: {class_names[predicted_class[0]]}\", f\"Probabilities per class: {probabilities.numpy()[0]}\"])\n",
    "no_preproc_real_check_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL ONLY ONCE\n",
    "\n",
    "# Create an empty dict to store results\n",
    "no_preproc_result_dict = {}\n",
    "\n",
    "# Start at test #1\n",
    "test_num_no_preproc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store test results\n",
    "# refer to result dict cell block above for comments\n",
    "no_preproc_result_dict[f'test_{test_num}'] = {\n",
    "    'fake_examples': {\n",
    "        'indices': fake_df.index.tolist(),\n",
    "        'scores': no_preproc_fake_check_list\n",
    "    },\n",
    "    'true_examples': {\n",
    "        'indices': true_df.index.tolist(),\n",
    "        'scores': no_preproc_real_check_list\n",
    "    }\n",
    "}\n",
    "test_num_no_preproc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The article is predicted as: Real', 'Probabilities per class: [0.56449354 0.43550646]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.5453537  0.45464623]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.94858193 0.05141811]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.7990511  0.20094892]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.6760489 0.3239511]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.5590448  0.44095516]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.59428835 0.4057117 ]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.7882812  0.21171874]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.7903143  0.20968564]']\n",
      "['The article is predicted as: Real', 'Probabilities per class: [0.85688585 0.14311416]']\n",
      "Accuracy (Fake NO Preprocessing) = 90%\n"
     ]
    }
   ],
   "source": [
    "# Calculate fake_df test accuracy\n",
    "# ------WITHOUT PREPROCESSING------\n",
    "# refer to test accuracy cell above for comments\n",
    "\n",
    "for test in no_preproc_result_dict.keys():\n",
    "    count = 0\n",
    "    for result in no_preproc_result_dict[test]['fake_examples']['scores']:\n",
    "        for row in result:\n",
    "            if \"Real\" in row:\n",
    "                count += 1\n",
    "                print(result)\n",
    "print(f'Accuracy (Fake NO Preprocessing) = {100 - count}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The article is predicted as: Fake', 'Probabilities per class: [0.24672669 0.7532733 ]']\n",
      "['The article is predicted as: Fake', 'Probabilities per class: [0.14297141 0.8570286 ]']\n",
      "Accuracy (True NO Preprocessing)= 98%\n"
     ]
    }
   ],
   "source": [
    "# Calculate true_df test accuracy\n",
    "# ------WITHOUT PREPROCESSING------\n",
    "# refer to test accuracy cell above for comments\n",
    "\n",
    "for test in no_preproc_result_dict.keys():\n",
    "    count = 0\n",
    "    for result in no_preproc_result_dict[test]['true_examples']['scores']:\n",
    "        for row in result:\n",
    "            if \"Fake\" in row:\n",
    "                count += 1\n",
    "                print(result)\n",
    "print(f'Accuracy (True NO Preprocessing)= {100 - count}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
